{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14898ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/dev/projects/AWID`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"../..\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01043f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (type = LinearAlgebra.Adjoint{Int64, Matrix{Int64}}): size = (130, 40000), first few values = [9204, 9520, 3493, 3550, 965] min = 1max = 12837\n",
      "y_train (type = BitMatrix): size = (1, 40000), first few values = Bool[1, 1, 0, 0, 1]\n",
      "X_test (type = LinearAlgebra.Adjoint{Int64, Matrix{Int64}}): size = (130, 10000), first few values = [3261, 286, 8278, 2453, 12585]\n",
      "y_test (type = BitMatrix): size = (1, 10000), first few values = Bool[1, 1, 0, 1, 0]\n",
      "embeddings (type = Matrix{Float32}): size = (50, 12837), first few values = Float32[0.014323 -0.58014 0.27137 0.68397 0.11369; -0.74624 -1.1316 0.61347 -0.68729 0.53461; 0.35701 0.44189 -0.52498 0.8797 1.2828; 0.75488 -0.048199 -0.7617 -0.35249 -0.61803; 0.11551 -0.11754 0.37252 0.82288 0.064278]\n",
      "vocab: length = 12837, first few values = [\"dev\", \"dumber\", \"henry\", \"abducted\", \"rises\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JLD2\n",
    "X_train = load(\"../../data/embeddings/imdb_dataset_prepared.jld2\", \"X_train\")\n",
    "y_train = load(\"../../data/embeddings/imdb_dataset_prepared.jld2\", \"y_train\")\n",
    "X_test = load(\"../../data/embeddings/imdb_dataset_prepared.jld2\", \"X_test\")\n",
    "y_test = load(\"../../data/embeddings/imdb_dataset_prepared.jld2\", \"y_test\")\n",
    "embeddings = load(\"../../data/embeddings/imdb_dataset_prepared.jld2\", \"embeddings\")\n",
    "vocab = load(\"../../data/embeddings/imdb_dataset_prepared.jld2\", \"vocab\")\n",
    "nothing\n",
    "\n",
    "println(\"X_train (type = \", typeof(X_train), \"): size = \", size(X_train), \", first few values = \", X_train[1:5], \" min = \", minimum(X_train), \"max = \", maximum(X_train))\n",
    "println(\"y_train (type = \", typeof(y_train), \"): size = \", size(y_train), \", first few values = \", y_train[1:5])\n",
    "println(\"X_test (type = \", typeof(X_test), \"): size = \", size(X_test), \", first few values = \", X_test[1:5])\n",
    "println(\"y_test (type = \", typeof(y_test), \"): size = \", size(y_test), \", first few values = \", y_test[1:5])\n",
    "println(\"embeddings (type = \", typeof(embeddings), \"): size = \", size(embeddings), \", first few values = \", embeddings[1:5,1:5])\n",
    "println(\"vocab: length = \", length(vocab), \", first few values = \", vocab[1:5])\n",
    "\n",
    "\n",
    "embedding_dim = size(embeddings, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94800753",
   "metadata": {},
   "outputs": [],
   "source": [
    "using AWID.NeuralNetwork, AWID.AutoDiff\n",
    "\n",
    "model = Chain(\n",
    "    Embedding(length(vocab), embedding_dim),\n",
    "    Conv((3,), embedding_dim, 8, relu),\n",
    "    MaxPool((8,)),\n",
    "    Flatten(),\n",
    "    Dense(128, 1, sigmoid)\n",
    ")\n",
    "\n",
    "# add Glove embeddings to Embedding layer\n",
    "model.layers[1].W.output .= embeddings;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319779c8",
   "metadata": {},
   "source": [
    "### Należy przepisać kod tak by w 'layers' był setup operatorów a działania na danych w operatorach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14618955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: Conv\n",
      "v: op.?(typeof(max))\n",
      "layer: MaxPool\n",
      "layer: Flatten\n",
      "layer: Dense\n",
      "layer: Conv\n",
      "v: op.?(typeof(max))\n",
      "layer: MaxPool\n",
      "layer: Flatten\n",
      "layer: Dense\n",
      "x_batch: (130, 64)\n",
      "y_batch: (1, 64)\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching forward(::AWID.AutoDiff.BroadcastedOperator{Variable{Matrix{Float32}}}, ::Matrix{Float32})\nThe function `forward` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  forward(::AWID.AutoDiff.BroadcastedOperator, ::Any, !Matched::Any)\n   @ AWID ~/dev/projects/AWID/src/AutoDiff/operators.jl:85\n  forward(!Matched::AWID.AutoDiff.BroadcastedOperator{typeof(/)}, ::Any, !Matched::Any)\n   @ AWID ~/dev/projects/AWID/src/AutoDiff/operators.jl:45\n  forward(!Matched::AWID.AutoDiff.BroadcastedOperator{typeof(softmax)}, ::Any)\n   @ AWID ~/dev/projects/AWID/src/AutoDiff/operators.jl:59\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching forward(::AWID.AutoDiff.BroadcastedOperator{Variable{Matrix{Float32}}}, ::Matrix{Float32})\n",
      "The function `forward` exists, but no method is defined for this combination of argument types.\n",
      "\n",
      "Closest candidates are:\n",
      "  forward(::AWID.AutoDiff.BroadcastedOperator, ::Any, !Matched::Any)\n",
      "   @ AWID ~/dev/projects/AWID/src/AutoDiff/operators.jl:85\n",
      "  forward(!Matched::AWID.AutoDiff.BroadcastedOperator{typeof(/)}, ::Any, !Matched::Any)\n",
      "   @ AWID ~/dev/projects/AWID/src/AutoDiff/operators.jl:45\n",
      "  forward(!Matched::AWID.AutoDiff.BroadcastedOperator{typeof(softmax)}, ::Any)\n",
      "   @ AWID ~/dev/projects/AWID/src/AutoDiff/operators.jl:59\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] compute!(node::AWID.AutoDiff.BroadcastedOperator{Variable{Matrix{Float32}}})\n",
      "   @ AWID.AutoDiff ~/dev/projects/AWID/src/AutoDiff/forward.jl:7\n",
      " [2] forward!(order::Vector{GraphNode})\n",
      "   @ AWID.AutoDiff ~/dev/projects/AWID/src/AutoDiff/forward.jl:12\n",
      " [3] _test_loss_and_accuracy(order::Vector{GraphNode}, y_pred_node::AWID.AutoDiff.BroadcastedOperator{typeof(AWID.AutoDiff.σ_internal)}, accuracy_fn::typeof(accuracy), y_test::BitMatrix)\n",
      "   @ AWID.NeuralNetwork.Training ~/dev/projects/AWID/src/NeuralNetwork/training.jl:20\n",
      " [4] _train_on_batch\n",
      "   @ ~/dev/projects/AWID/src/NeuralNetwork/training.jl:11 [inlined]\n",
      " [5] (::AWID.NeuralNetwork.Training.var\"#2#4\"{Chain, typeof(accuracy), Adam, Vector{GraphNode}, AWID.AutoDiff.BroadcastedOperator{typeof(AWID.AutoDiff.σ_internal)}, Constant{Matrix{Float32}}, Variable{Matrix{Float32}}})(x_batch::Matrix{Int64}, y_batch::BitMatrix)\n",
      "   @ AWID.NeuralNetwork.Training ~/dev/projects/AWID/src/NeuralNetwork/training.jl:40\n",
      " [6] macro expansion\n",
      "   @ ~/dev/projects/AWID/notebooks/KM3/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W4sZmlsZQ==.jl:27 [inlined]\n",
      " [7] macro expansion\n",
      "   @ ./timing.jl:421 [inlined]\n",
      " [8] top-level scope\n",
      "   @ ~/dev/projects/AWID/notebooks/KM3/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W4sZmlsZQ==.jl:23"
     ]
    }
   ],
   "source": [
    "using AWID.NeuralNetwork, AWID.AutoDiff, Printf\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_on_batch, test_loss_and_accuracy = setup_training_functions(\n",
    "    model=model,\n",
    "    loss_fn=binary_crossentropy,\n",
    "    accuracy_fn=accuracy,\n",
    "    optimizer=Adam(),\n",
    "    x_test=X_test,\n",
    "    y_test=y_test,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "for epoch in 1:epochs\n",
    "    epoch_total_loss = 0.0f0\n",
    "    epoch_total_acc = 0.0f0\n",
    "    num_processed_batches = 0\n",
    "\n",
    "    epoch_batches = get_epoch_batches(X_train, y_train, batch_size=batch_size, do_shuffle=true)\n",
    "\n",
    "    t = @elapsed begin\n",
    "        for (x_batch, y_batch) in epoch_batches\n",
    "            println(\"x_batch: \", size(x_batch))\n",
    "            println(\"y_batch: \", size(y_batch))\n",
    "            batch_loss, batch_acc = train_on_batch(x_batch, y_batch)\n",
    "\n",
    "            epoch_total_loss += batch_loss\n",
    "            epoch_total_acc += batch_acc\n",
    "            num_processed_batches += 1\n",
    "        end\n",
    "\n",
    "        train_loss = epoch_total_loss / num_processed_batches\n",
    "        train_acc = epoch_total_acc / num_processed_batches\n",
    "\n",
    "        test_loss, test_acc = test_loss_and_accuracy()\n",
    "    end\n",
    "\n",
    "    println(@sprintf(\"Epoch: %d (%.2fs) \\tTrain: (l: %.2f, a: %.2f) \\tTest: (l: %.2f, a: %.2f)\",\n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc))\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
